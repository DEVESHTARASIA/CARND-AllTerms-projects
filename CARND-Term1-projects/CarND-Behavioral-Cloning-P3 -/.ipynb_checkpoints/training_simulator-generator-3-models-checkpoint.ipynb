{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "correction = 0.2 #angle correction for left/right cameras\n",
    "total_cameras = 3 #use right and left cameras too\n",
    "batch_size = 128\n",
    "\n",
    "# training dataset \n",
    "base_path = '../data/data_small'\n",
    "#base_path = '../data/data_xbox'\n",
    "#base_path = '../data/data_udacity'\n",
    "#base_path = '/Users/albertoescarlate/Desktop'\n",
    "\n",
    "# resizing values\n",
    "new_w = 64\n",
    "new_h = 64\n",
    "\n",
    "# chosen model\n",
    "#CNN_model = \"LeNet\"\n",
    "#CNN_model = \"NVIDIA\"\n",
    "CNN_model = \"comma_ai\"\n",
    "\n",
    "epoch = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "# flip images horizontally\n",
    "def flip_image(img, angle):\n",
    "    img = cv2.flip(img, 1)\n",
    "    angle = angle * -1.0\n",
    "    return img, angle\n",
    "\n",
    "def normalize_image(img):\n",
    "    img = (img / 255.) - 0.5\n",
    "    return img\n",
    "\n",
    "def convert_color_image(img):\n",
    "    img=img.astype(np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    return img\n",
    "\n",
    "# crop bottom 25 pixels + crop 33.3% of image top (scenery above road) + resize it to 64 x 64\n",
    "def crop_resize_image(img):\n",
    "    shape = img.shape\n",
    "    img = img[math.floor(shape[0]/3):shape[0]-25, 0:shape[1]]\n",
    "    img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)    \n",
    "    return img\n",
    "\n",
    "# flip input image\n",
    "def process_image(img, angle):\n",
    "    if abs(angle) < 0.05:\n",
    "        pass\n",
    "    if random() > 0.5:\n",
    "        img, angle = flip_image(img, angle)\n",
    "    img = normalize_image(img)\n",
    "    img = convert_color_image(img)\n",
    "    img = crop_resize_image(img)\n",
    "    return img, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(sample):\n",
    "    path = base_path + '/IMG/'\n",
    "\n",
    "    source_center = sample[0]    \n",
    "    name_center = path + source_center.split('/')[-1]\n",
    "    image_center = cv2.imread(name_center)\n",
    "    angle_center = float(sample[3])\n",
    "\n",
    "    source_left = sample[1]\n",
    "    name_left = path + source_left.split('/')[-1]\n",
    "    image_left = cv2.imread(name_left)\n",
    "    angle_left = angle_center + correction\n",
    "\n",
    "    source_right = sample[2]\n",
    "    name_right = path + source_right.split('/')[-1]\n",
    "    image_right = cv2.imread(name_right)\n",
    "    angle_right = angle_center - correction\n",
    "\n",
    "    return (image_center, image_right, image_left), (angle_center, angle_right, angle_left)\n",
    "            \n",
    "def generator(samples, batch_size, total_cameras=3):\n",
    "    num_samples = len(samples)\n",
    "    while 1: \n",
    "        sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                image, angle = load_data(batch_sample)\n",
    "                for item in zip(image,angle): #iterate camera images and  steering angles\n",
    "                    aug_image, aug_angle = process_image(item[0], item[1])\n",
    "                    images.append(aug_image)\n",
    "                    angles.append(aug_angle)\n",
    "                \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_LeNet():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1., input_shape=(64,64,3), output_shape=(64,64,3)))\n",
    "    model.add(Convolution2D(6, 5, 5, border_mode=\"same\", activation='elu', name='Conv1'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Convolution2D(6, 5, 5, border_mode=\"same\", activation='elu', name='Conv2'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120, activation='elu', name='FC1'))\n",
    "    model.add(Dense(84, activation='elu', name='FC2'))\n",
    "    model.add(Dense(1, activation='elu', name='output'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_comma_ai():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1., input_shape=(64, 64, 3), output_shape=(64, 64, 3)))\n",
    "    model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\", activation='elu', name='conv1'))\n",
    "    model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\", activation='elu', name='conv2'))\n",
    "    model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\", activation='elu', name='conv3'))\n",
    "    model.add(Flatten(name='flat'))\n",
    "    model.add(Dropout(0.5, name='drop1'))\n",
    "    model.add(ELU(name='elu1'))\n",
    "    model.add(Dense(512, activation='elu', name='fully_connected1'))\n",
    "    model.add(Dropout(0.5, name='drop2'))\n",
    "    model.add(ELU(name='elu2'))\n",
    "    model.add(Dense(1, name='output'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_NVIDIA():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1., input_shape=(64, 64, 3), output_shape=(64, 64, 3)))\n",
    "    model.add(Convolution2D(24,5,5, border_mode=\"same\", activation='elu', name='conv1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(36,5,5, border_mode=\"same\", activation='elu', name='conv2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(48,5,5, border_mode=\"same\", activation='elu', name='conv3'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64,3,3, border_mode=\"same\", activation='elu', name='conv4'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64,3,3, border_mode=\"same\", activation='elu', name='conv5'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten(name='flat'))\n",
    "    model.add(Dense(100, activation='elu', name='fully_connected1'))\n",
    "    model.add(Dense(50, activation='elu', name='fully_connected2'))\n",
    "    model.add(Dense(10, activation='elu', name='fully_connected3'))\n",
    "    model.add(Dense(1, activation='elu', name='output'))\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/data_small/driving_log.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/data_small/driving_log.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-26799e3207b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/driving_log.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/data_small/driving_log.csv'"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "path = base_path + '/driving_log.csv'\n",
    "print(path)\n",
    "with open(path) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = generator(train_samples, batch_size=10)\n",
    "sample_images, sample_steerings = iterator.__next__()\n",
    "\n",
    "plt.subplots(figsize=(20, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Steering: {:.4f}\".format(sample_steerings[i]))\n",
    "    plt.imshow(sample_images[i], cmap='Accent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Flatten, Lambda, ELU, Cropping2D, Input, MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.regularizers import l2\n",
    "\n",
    "CNN_model = \"LeNet\"\n",
    "\n",
    "if CNN_model == \"comma_ai\":\n",
    "    model = model_comma_ai()\n",
    "else:\n",
    "    if CNN_model == \"LeNet\":\n",
    "        model = model_LeNet() \n",
    "    else:\n",
    "        if CNN_model == \"NVIDIA\":\n",
    "            model = model_NVIDIA()\n",
    "\n",
    "# calculate samples/epoch and validation samples\n",
    "num_samples_per_epoch = math.ceil(len(train_samples)*3 / batch_size)* batch_size\n",
    "print(\"num_samples_per_epoch\",num_samples_per_epoch)\n",
    "num_val_samples = math.ceil(len(validation_samples)*3 / batch_size) * batch_size\n",
    "print(\"num_val_samples\",num_samples_per_epoch)            \n",
    "            \n",
    "model.summary()\n",
    "\n",
    "#adam = Adam(lr=0.0001)\n",
    "model.compile(loss='mse', optimizer='Adam')\n",
    "\n",
    "\n",
    "history_object = model.fit_generator(train_generator, \n",
    "                    samples_per_epoch=num_samples_per_epoch, \n",
    "                    validation_data=validation_generator,\n",
    "                    nb_val_samples=num_val_samples, \n",
    "                    nb_epoch=epoch)\n",
    "\n",
    "model.save('model.h5')\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
